{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open appendix-keywords.txt\n",
    "with open(\"./appendix-keywords.txt\") as f:\n",
    "    file = f.read()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    # Specifies the delimiter used to split the text\n",
    "    separator=\"\\n\\n\",\n",
    "    # the maximum size of each text chunk in terms of the number of characters\n",
    "    chunk_size=210,\n",
    "    # Specifies the number of overlapping characters between consecutive chunks\n",
    "    chunk_overlap=0,\n",
    "    # function used to calculate the length of the text (default \"len\")\n",
    "    length_function=len,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line uses the text_splitter object to split the text from the file into chunks\n",
    "texts = text_splitter.create_documents([file])\n",
    "\n",
    "print(len(texts[0].page_content)) \n",
    "print(texts[0])  \n",
    "\n",
    "''' text[0] may look like this\n",
    "\n",
    "{\n",
    "    \"page_content\": \"This is the first chunk of text.\",\n",
    "    \"metadata\": {\n",
    "        \"source\": \"file.txt\",\n",
    "        \"chunk_index\": 0\n",
    "    }\n",
    "} '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadatas = [\n",
    "    {\"document\": 1},\n",
    "    {\"document\": 2},\n",
    "]  \n",
    "documents = text_splitter.create_documents(\n",
    "    [\n",
    "        file,\n",
    "        file,\n",
    "    ],  \n",
    "    metadatas=metadatas,  \n",
    ")\n",
    "print(documents[0])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # 청크 크기를 매우 작게 설정합니다. 예시를 위한 설정입니다.\n",
    "    chunk_size=250,\n",
    "    # 청크 간의 중복되는 문자 수를 설정합니다.\n",
    "    chunk_overlap=50,\n",
    "    # 문자열 길이를 계산하는 함수를 지정합니다.\n",
    "    length_function=len,\n",
    "    # 구분자로 정규식을 사용할지 여부를 설정합니다.\n",
    "    is_separator_regex=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_splitter를 사용하여 file 텍스트를 문서로 분할합니다.\n",
    "texts = text_splitter.create_documents([file])\n",
    "print(texts[0])  # 분할된 문서의 첫 번째 문서를 출력합니다.\n",
    "print(\"===\" * 20)\n",
    "print(texts[1])  # 분할된 문서의 두 번째 문서를 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트를 분할하고 분할된 텍스트의 처음 2개 요소를 반환합니다.\n",
    "text_splitter.split_text(file)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a proxy to bypass network restrictions or anonymize the connection\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    \"https://www.google.com/search?q=parrots\",\n",
    "    proxies={\n",
    "        \"http\": \"http://{username}:{password}:@proxy.service.com:6666/\",\n",
    "        \"https\": \"https://{username}:{password}:@proxy.service.com:6666/\",\n",
    "    },\n",
    "\n",
    ")\n",
    "\n",
    "docs = loader.load()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
