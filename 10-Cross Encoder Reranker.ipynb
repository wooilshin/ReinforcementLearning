{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Cross Encoder Reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieval Ranking\n",
    "# Role: Searches and ranks relevant documents from a large collection during the initial stage.\n",
    "# Methods:\n",
    "# - Sparse Retrieval: Uses traditional models like TF-IDF or BM25.\n",
    "# - Dense Retrieval: Employs bi-encoders to separately embed queries and documents, computing similarity (e.g., cosine similarity).\n",
    "\n",
    "# Cross Encoder Reranking\n",
    "# Role: Re-ranks the top-k documents retrieved during the initial stage for better relevance.\n",
    "# Mechanism:\n",
    "# Combines the query and document as a single input to analyze their semantic relationship using self-attention.\n",
    "# Outputs a relevance score for each query-document pair.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load Documents\n",
    "documents = TextLoader(\"./data/appendix-keywords.txt\").load()\n",
    "\n",
    "# Text Splitting\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# Embedding Model Setup\n",
    "embeddingsModel = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/msmarco-distilbert-dot-v5\"\n",
    ")\n",
    "\n",
    "# Use FAISS to create an index from the text chunks, then set up a retriever to search the index with top-k results (k=10)\n",
    "retriever = FAISS.from_documents(texts, embeddingsModel).as_retriever(\n",
    "    search_kwargs={\"k\": 10}\n",
    ")\n",
    "\n",
    "# Query and Retrieve Results\n",
    "query = \"What is monetary policy like in Korea?\"\n",
    "\n",
    "\n",
    "# Embeds the query using the HuggingFaceEmbeddings model and performs a similarity search in the FAISS index using the query's embedding\n",
    "docs = retriever.invoke(query)\n",
    "\n",
    "pretty_print_docs(docs)\n",
    "\n",
    "# So far, The query and document embeddings are computed independently using the Hugging Face model (msmarco-distilbert-dot-v5).\n",
    "# Now we The query and document are processed together as a single input through a model by cross encoder\n",
    "\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "\n",
    "# Cross Encoder Initialization\n",
    "model = HuggingFaceCrossEncoder(model_name=\"BAAI/bge-reranker-v2-m3\")\n",
    "\n",
    "# The CrossEncoderReranker is initialized with the model and configured to select the top 3 most relevant documents (top_n=3)\n",
    "compressor = CrossEncoderReranker(model=model, top_n=3)\n",
    "\n",
    "# ContextualCompressionRetriever\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=retriever\n",
    ")\n",
    "\n",
    "# Query Execution\n",
    "compressed_docs = compression_retriever.invoke(\"What is monetary policy like in Korea?\")\n",
    "\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
