{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> PDF loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = \"./IMF_gfsr.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_metadata(docs):\n",
    "    if docs:\n",
    "        print(\"[metadata]\")\n",
    "        print(list(docs[0].metadata.keys()))\n",
    "        print(\"\\n[examples]\")\n",
    "        max_key_length = max(len(k) for k in docs[0].metadata.keys())\n",
    "        for k, v in docs[0].metadata.items():\n",
    "            print(f\"{k:<{max_key_length}} : {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyPDF\n",
    "# !pip install -qU pypdf\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(FILE_PATH)\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "print(docs[10].page_content[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDFplumber\n",
    "\n",
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "\n",
    "loader = PDFPlumberLoader(FILE_PATH)\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "print(docs[10].page_content[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> CSVloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "# CSV 로더 생성\n",
    "loader = CSVLoader(file_path=\"./interestrate.csv\")\n",
    "\n",
    "# 데이터 로드\n",
    "docs = loader.load()\n",
    "\n",
    "print(len(docs))\n",
    "print(docs[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert its rows into an XML-like structure for further processing or transformation\n",
    "# Example \n",
    "# Date,US 10yr Interest Rate,KOR 10yr Interest Rate\n",
    "# 2024-11-20, 3.5, 2.3\n",
    "# 2024-11-19, 4.2, 2.0\n",
    "#\n",
    "# <row><Date>2024-11-20</Date><US 10yr Interest Rate>3.5</US 10yr Interest Rate><KOR 10yr Interest Rate>2.3</KOR 10yr Interest Rate></row>\n",
    "# <row><Date>2024-11-19</Date><US 10yr Interest Rate>4.2</US 10yr Interest Rate><KOR 10yr Interest Rate>2.0</KOR 10yr Interest Rate></row>\n",
    "\n",
    "# splits the content of the document into individual elements\n",
    "row = docs[1].page_content.split(\"\\n\")\n",
    "\n",
    "# The structure is concatenated into a single <row>...</row> string\n",
    "row_str = \"<row>\"\n",
    "for element in row:\n",
    "    splitted_element = element.split(\":\")\n",
    "    value = splitted_element[-1]\n",
    "    col = \":\".join(splitted_element[:-1])\n",
    "    row_str += f\"<{col}>{value.strip()}</{col}>\"\n",
    "row_str += \"</row>\"\n",
    "print(row_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unlike CSV, XML can encode entity relationships by defining a structured, hierarchical format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> WebBasedLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    # Specifies the URL of the web page to scrape\n",
    "    web_paths=(\"https://n.news.naver.com/article/437/0000378416\",),\n",
    "    \n",
    "    # Passes options to BeautifulSoup to extract specific sections of the HTML (This is the core)\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            \"div\",\n",
    "            attrs={\"class\": [\"newsct_article _article_body\", \"media_end_head_title\"]},  # 브라우저에서 검사 누르고 가져올 부분 지정 \n",
    "        )\n",
    "    ),\n",
    "    # Headers mimic a browser request to avoid getting blocked (warning) by the server\n",
    "    header_template={\n",
    "        \"User_Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# Configure the requests_kwargs attribute to set custom SSL behavior\n",
    "loader.requests_kwargs = {\"verify\": True}\n",
    "\n",
    "# Loading Documents\n",
    "docs = loader.load()\n",
    "print(f\"문서의 수: {len(docs)}\")\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a proxy to bypass network restrictions or anonymize the connection\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    \"https://www.google.com/search?q=parrots\",\n",
    "    proxies={\n",
    "        \"http\": \"http://{username}:{password}:@proxy.service.com:6666/\",\n",
    "        \"https\": \"https://{username}:{password}:@proxy.service.com:6666/\",\n",
    "    },\n",
    "\n",
    ")\n",
    "\n",
    "docs = loader.load()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
